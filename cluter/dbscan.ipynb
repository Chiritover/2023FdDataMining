{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "class DBSCAN(object):\n",
    "\n",
    "    STATUS_UNVISITED = 'unvisited'\n",
    "    STATUS_VISITED = 'visited'\n",
    "\n",
    "    STATUS_GROUP = 1\n",
    "    STATUS_NOGROUP = 0\n",
    "\n",
    "    data = dict()\n",
    "\n",
    "    def __init__(self, e, minPts):\n",
    "        \"\"\"\n",
    "        e 最小距离\n",
    "        minPts 最少样本数量\n",
    "        \"\"\"\n",
    "        self.e = e\n",
    "        self.minPts = minPts\n",
    "\n",
    "    def nearby(self, id):\n",
    "        nearby_points = list()\n",
    "        for link_id in range(len(self.scores[id])):\n",
    "            if self.scores[id][link_id] <= self.e:\n",
    "                nearby_points.append(link_id)\n",
    "\n",
    "        return nearby_points\n",
    "\n",
    "    def visit_nearby_points(self, points, group):\n",
    "        for id in points:\n",
    "            if self.data[id]['is_visited'] == self.STATUS_VISITED \\\n",
    "                    and self.data[id]['is_group'] == self.STATUS_GROUP:\n",
    "                continue\n",
    "            self.data[id]['is_visited'] = self.STATUS_VISITED\n",
    "\n",
    "            if self.data[id]['is_group'] == self.STATUS_NOGROUP:\n",
    "                group.append(id)\n",
    "                self.data[id]['is_group'] = self.STATUS_GROUP\n",
    "\n",
    "            nearby_points = self.nearby(id)\n",
    "            if len(nearby_points) >= self.minPts:\n",
    "                self.visit_nearby_points(nearby_points, group)\n",
    "\n",
    "    def fit(self, data_set, scores):\n",
    "        self.scores = scores\n",
    "        groups = list()\n",
    "\n",
    "        for index, item in enumerate(data_set):\n",
    "           self.data[index] = {'id': index,\n",
    "                                'is_visited': self.STATUS_UNVISITED,\n",
    "                                'is_group': self.STATUS_NOGROUP\n",
    "                                }\n",
    "        print(index)\n",
    "\n",
    "        for id in self.data:\n",
    "            if self.data[id]['is_visited'] == self.STATUS_VISITED:\n",
    "                continue\n",
    "\n",
    "            self.data[id]['is_visited'] = self.STATUS_VISITED\n",
    "            nearby_points = self.nearby(id)\n",
    "\n",
    "            if len(nearby_points) >= self.minPts:\n",
    "                group = list()\n",
    "                group.append(id)\n",
    "                self.data[id]['is_group'] = self.STATUS_GROUP\n",
    "                self.visit_nearby_points(nearby_points, group)\n",
    "                groups.append(group)\n",
    "\n",
    "        for id in self.data:\n",
    "            if self.data[id]['is_group'] == self.STATUS_NOGROUP:\n",
    "                groups.append([id])\n",
    "\n",
    "        return groups\n",
    "\n",
    "\n",
    "def init_data(num, min, max):\n",
    "    data = []\n",
    "    for i in range(num):\n",
    "        data.append([random.randint(min, max), random.randint(min, max)])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def mat_score(data_set):\n",
    "    score = dict()\n",
    "    for i in range(len(data_set)):\n",
    "        score[i] = dict()\n",
    "\n",
    "    for i in range(len(data_set) - 1):\n",
    "        j = i + 1\n",
    "        while j < len(data_set):\n",
    "            score[i][j] = math.sqrt(abs(data_set[i][0] - data_set[j][0]) ** 2 + abs(data_set[i][1] - data_set[j][1]) ** 2)\n",
    "            score[j][i] = score[i][j]\n",
    "            j += 1\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# def show_cluster(data_set, groups):\n",
    "#     plt.title(u'DBSCAN')\n",
    "#     mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "#     for index, group in enumerate(groups):\n",
    "#         for i in group:\n",
    "#             plt.plot(data_set[i][0], data_set[i][1], mark[index])\n",
    "\n",
    "#     plt.xlim(0.0, 100)\n",
    "#     plt.ylim(0.0, 100)\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33715, 768)\n",
      ">>> t-SNE fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15957\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\manifold\\_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\15957\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\manifold\\_t_sne.py:996: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< fitting over\n",
      "(33715, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "\n",
    "#导入npy文件路径位置\n",
    "test = np.load('C:\\\\Users\\\\15957\\\\Desktop\\\\2023\\\\data mining\\\\project\\\\npy_embs\\\\ift_cluster_given_fudandm2023-input-bert-base-chinese.npy')\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\">>> t-SNE fitting\")\n",
    "tsne = TSNE(n_components=2, init='pca', perplexity=30)\n",
    "Y = tsne.fit_transform(test)\n",
    "print(f\"<<< fitting over\")\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-13.63955   -6.073564]\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])\n",
    "np.save(\"2demb\",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for i in range(20):\n",
    "    dist = []\n",
    "    for j in range(20):\n",
    "        dist.append(np.linalg.norm(np.array(Y[i]) - np.array(Y[j])))\n",
    "    dists.append(dist)\n",
    "   \n",
    "print(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.23 GiB for an array with shape (33715, 33715) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.23 GiB for an array with shape (33715, 33715) and data type float32"
     ]
    }
   ],
   "source": [
    "# scores = np.array(dists)\n",
    "# print(scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = np.load(\"2demb.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dists.txt\",\"w\") as f:\n",
    "    for i in range(len(Y) - 1):\n",
    "        j = 0\n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "        while j < len(Y):\n",
    "            dist = np.linalg.norm(np.array(Y[i]) - np.array(Y[j]))\n",
    "            f.write(str(dist))\n",
    "            f.write(\" \")\n",
    "            j += 1\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 2)\n",
      "(20, 20)\n",
      "19\n",
      "[[0, 2, 3, 4, 5, 6, 1, 7, 9, 8, 10, 11, 12, 13, 15, 14, 18, 16, 19, 17]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(20):\n",
    "    data.append(Y[i])\n",
    "model = DBSCAN(50,50)\n",
    "data = np.array(data)\n",
    "dists = np.array(dists)\n",
    "print(data.shape)\n",
    "print(dists.shape)\n",
    "cluster = model.fit(data, dists)\n",
    "print(cluster)\n",
    "np.save('dbscan', cluster)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
